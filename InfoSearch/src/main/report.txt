Информационный поиск
алгоритм:
1. считываем тезаурус
    1.1 считываем дескрипторы, лемматизируем синсеты
    1.2 проставляем иерархические отношения между ними
2. потекстово считываем корпус
3. считываем запросы, добавляя их в корпус как тексты
4. подсчитываем IDF
5. подсчитываем TFIDF
6. нормализуем полученные векторы для каждого текста
7. считаем релевантность на основе косинуса угла векторами запроса и каждого текста
8. сортируем на основе полученной релевантности
9. выводим результаты

"хорошие запросы"
recall: 72.3%
precision: 74.5%
f1-score: 73.383

любые запросы(включая короткие запросы, запросы, к текстам, которых нет в корпусе, и содержащие слова, не входящие в тезаурус)
recall: 36 %
precision: 47 %
f1 = 40.7 %

как получили:
precision - по формулу
recall - были выбраны наиболее удачные запросы. Под ними понимаются длинные запросы, ответы на которые гарантированно содержатся в тексте (таким образом увеличиваем выборку, делая её более репрезентативной).
Под длиной подразумевается, что запрос содержит хотя бы 4 ненулевые координаты в пространстве состояний (если будет иначе, произойдет ситуация, описанная в анализе ошибок). После этого по ключевым словам находим
тексты, которые не вошли в ответ и подсчитываем их количество.


Анализ ошибок:

Плохие результаты на коротких запросах. Это ожидаемое поведение косинусной метрики. Короткие запросы как правило содержат 1-2 ненулевых координат в пространстве признаков,
в то время как текст в среднем содержит 6-8. Это означает, что даже подходящие под запрос векторы, оказываются на приличном расстоянии от запроса.
Если бы мы правда писали поисковую систему, то разумной идеей был бы выбор иной метрики или применение методов редуцирования размерности пространства,
в соответствии с запросом. Но делать этого мы конечно не будем.

Также влияет то, что вектор для текста содержит только найденные в нем дескрипторы, а размер тезауруса всего 54 дескриптора.